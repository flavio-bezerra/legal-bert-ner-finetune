# âš–ï¸ Legal Risk Extractor: Auditoria Contratual com Legal-BERT & MLOps

![Python](https://img.shields.io/badge/Python-3.10%2B-blue)
![Hugging Face](https://img.shields.io/badge/ðŸ¤—%20Transformers-Legal--BERT-yellow)
![MLflow](https://img.shields.io/badge/MLflow-Managed-blue)
![Optuna](https://img.shields.io/badge/Optuna-Hyperparameter%20Tuning-orange)

> **Auditoria automatizada de riscos em contratos de alta volumetria usando NLP Especializado (NER), com custo 100x menor que LLMs Generativos.**

---

## ðŸŽ¯ VisÃ£o Executiva & Contexto de NegÃ³cio

Em cenÃ¡rios de M&A (FusÃµes e AquisiÃ§Ãµes) ou Auditoria de Compliance, empresas precisam revisar milhares de contratos legados para identificar riscos ocultos, como **ClÃ¡usulas de Multa**, **Foro de EleiÃ§Ã£o** ou **Datas de TÃ©rmino AutomÃ¡tico**.

**Por que nÃ£o usar GPT-4?**
Embora LLMs sejam poderosos, processar 1 milhÃ£o de pÃ¡ginas via API gera:

1.  **Custo Proibitivo:** Alto custo por token, tornando inviÃ¡vel para varreduras massivas.
2.  **LatÃªncia:** APIs generativas sÃ£o lentas; este modelo roda em milissegundos localmente.
3.  **Privacidade/Compliance:** Envio de dados confidenciais para APIs externas pode violar NDAs rigorosos.

**A SoluÃ§Ã£o:** Este projeto implementa um modelo **Legal-BERT (110M parÃ¢metros)** fine-tuned, otimizado para extraÃ§Ã£o de entidades jurÃ­dicas (NER) em contratos longos, oferecendo velocidade, privacidade e custo marginal zero.

---

## ðŸ—ï¸ Arquitetura TÃ©cnica

### 1. Superando o Limite de 512 Tokens (Robust Sliding Windows)

Contratos reais excedem o limite de contexto do BERT.

- **EstratÃ©gia:** ImplementaÃ§Ã£o de Janelas Deslizantes (`stride=128`, `max_length=512`).
- **AgregaÃ§Ã£o:** Um pipeline de pÃ³s-processamento reconstrÃ³i as entidades que foram "cortadas" na divisa das janelas, garantindo integridade semÃ¢ntica.

### 2. OtimizaÃ§Ã£o de HiperparÃ¢metros (Bayesian Search)

Em vez de "chutar" learning rates, utilizei **Optuna** para realizar uma busca Bayesiana, maximizando o F1-Score no conjunto de validaÃ§Ã£o e encontrando a convergÃªncia ideal para o dataset jurÃ­dico.

### 3. Engenharia de Dados Robusta & CorreÃ§Ã£o de ViÃ©s

- **PrevenÃ§Ã£o de Data Leakage:** Split de dados realizado por _Document ID_, garantindo que trechos do mesmo contrato nunca apareÃ§am simultaneamente no treino e teste.
- **Tratamento de Labels:** InicializaÃ§Ã£o explÃ­cita de tokens "Outside" ('O') e **Negative Downsampling** para lidar com o desbalanceamento extremo (99% do texto jurÃ­dico nÃ£o Ã© entidade de interesse).

### 4. BÃ´nus: QuantizaÃ§Ã£o (INT8)

O modelo final inclui uma etapa de **QuantizaÃ§Ã£o DinÃ¢mica**, reduzindo o tamanho do modelo em 4x e acelerando a inferÃªncia na CPU, ideal para deploy em ambientes com recursos limitados (Edge/Serverless).

---

## âš™ï¸ MLOps Pipeline

O ciclo de vida do modelo foi gerenciado utilizando **MLflow**:

- **Tracking:** Log automÃ¡tico de mÃ©tricas (Loss, Precision, Recall, F1).
- **Artifacts:** Salvamento auditÃ¡vel de grÃ¡ficos de diagnÃ³stico (Curvas de Aprendizado, Matriz de ConfusÃ£o).
- **Model Registry:** Versionamento de modelos com status (Staging -> Production).

---

## ðŸ“Š Resultados

O modelo final atingiu performance competitiva para varredura automatizada:

| MÃ©trica      | Valor (ValidaÃ§Ã£o)\* | Significado                                                       |
| :----------- | :------------------ | :---------------------------------------------------------------- |
| **F1-Score** | **~90%+**           | MÃ©dia harmÃ´nica (EquilÃ­brio entre precisÃ£o e cobertura).          |
| Precision    | Alta                | Quando o modelo aponta um risco, ele Ã© fidedigno.                 |
| Recall       | Alta                | O modelo captura a vasta maioria das clÃ¡usulas crÃ­ticas de risco. |

_(Resultados aproximados dependentes da rodada de otimizaÃ§Ã£o Bayesiana)._

---

## ðŸš€ Como Usar

### InstalaÃ§Ã£o

```bash
pip install transformers datasets seqeval accelerate evaluate torch pandas mlflow optuna
```

### InferÃªncia (SimulaÃ§Ã£o de ProduÃ§Ã£o)

O notebook inclui um wrapper `predict_long_contract` que abstrai a complexidade do janelamento.

```python
from transformers import pipeline

# Carregar modelo treinado
model_path = "./legal-bert-ner-production/final_model"
pipe = pipeline("token-classification", model=model_path, tokenizer=model_path, aggregation_strategy="simple")

texto_contrato = """
SECTION 10. GOVERNING LAW. This Agreement shall be governed by the laws of the State of Sao Paulo.
"""

resultado = pipe(texto_contrato)
print(resultado)
# Output esperado: [{'entity_group': 'Governing Law', 'word': 'State of Sao Paulo', ...}]
```

---

## ðŸ“‚ Estrutura do Projeto

```text
.
â”œâ”€â”€ legal_ner_finetune_final_polished.ipynb  # Notebook Principal (End-to-End)
â”œâ”€â”€ mlruns/                                  # Logs de experimentaÃ§Ã£o do MLflow
â”œâ”€â”€ legal-bert-ner-production/               # Artifacts do modelo final salvo
â””â”€â”€ README.md                                # DocumentaÃ§Ã£o do Projeto
```

---

_Desenvolvido como case de Engenharia de Machine Learning focado em NLP JurÃ­dico._
